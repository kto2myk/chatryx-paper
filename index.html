<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>解釈可能な機械学習：非線形決定木モデル特徴量分析SPA</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
    <!-- Visualization & Content Choices:
        - Report Text Sections (Introduction, SHAP, PFI, Friedman's H, CatBoost Interactions, PDP, ICE, ALE, Categorical Encoding, Combining Methods, Summary): Presented in styled HTML paragraphs and lists. Goal: Inform, Explain. Method: Tailwind CSS for typography and layout.
        - Mathematical Formulas: Displayed as text within paragraphs (preserving LaTeX-like syntax from source). Goal: Detail. Method: Standard text.
        - Illustrative Feature Importance Chart: A Chart.js bar chart to visually represent the concept of feature importance. Goal: Illustrate concept. Method: Chart.js Bar Chart. Data: Static, representative. Library: Chart.js.
        - Comparison Tables (Table 1: Main analysis methods, Table 2: Categorical encoding): Rendered as HTML tables styled with Tailwind. Goal: Compare, Summarize. Method: HTML table + Tailwind.
        - Navigation: Clickable sidebar links to show/hide respective content sections. Goal: Navigate. Method: JavaScript.
        - CONFIRMATION: NO SVG graphics used. NO Mermaid JS used. -->
    <style>
        body { font-family: 'Inter', sans-serif; }
        .content-section { display: none; }
        .content-section.active { display: block; }
        .nav-link { transition: all 0.3s ease; }
        .nav-link.active, .nav-link:hover { background-color: #0ea5e9; color: white; } /* sky-500 */
        .chart-container {
            position: relative;
            width: 100%;
            max-width: 600px; /* Adjusted for better fit */
            margin-left: auto;
            margin-right: auto;
            height: 300px;
            max-height: 400px; /* sm:h-80 md:h-96 */
        }
        @media (min-width: 768px) {
            .chart-container {
                height: 350px;
            }
        }
        table th, table td { border: 1px solid #e5e7eb; padding: 8px; text-align: left; }
        table th { background-color: #f3f4f6; }
    </style>
</head>
<body class="bg-stone-100 text-stone-800">
    <div class="flex flex-col md:flex-row min-h-screen">
        <nav class="md:w-64 bg-stone-50 p-4 shadow-lg md:sticky md:top-0 md:h-screen overflow-y-auto">
            <h1 class="text-2xl font-bold text-sky-700 mb-6 border-b pb-3">目次</h1>
            <ul class="space-y-2">
                <li><a href="#introduction" class="nav-link block p-2 rounded-lg font-medium text-stone-700">1. はじめに</a></li>
                <li><a href="#feature-importance" class="nav-link block p-2 rounded-lg font-medium text-stone-700">2. 特徴量重要度分析</a></li>
                <li><a href="#feature-interaction" class="nav-link block p-2 rounded-lg font-medium text-stone-700">3. 特徴量相互作用分析</a></li>
                <li><a href="#individual-feature-analysis" class="nav-link block p-2 rounded-lg font-medium text-stone-700">4. 各特徴量の役割分析</a></li>
                <li><a href="#categorical-features" class="nav-link block p-2 rounded-lg font-medium text-stone-700">5. カテゴリ特徴量</a></li>
                <li><a href="#practical-approach" class="nav-link block p-2 rounded-lg font-medium text-stone-700">6. 実践的アプローチ</a></li>
                <li><a href="#comparison-tables" class="nav-link block p-2 rounded-lg font-medium text-stone-700">7. 手法比較表</a></li>
                <li><a href="#summary" class="nav-link block p-2 rounded-lg font-medium text-stone-700">8. まとめと今後の展望</a></li>
            </ul>
        </nav>

        <main class="flex-1 p-6 md:p-10 overflow-y-auto">
            <header class="mb-8 text-center">
                <h1 class="text-4xl font-bold text-sky-800">解釈可能な機械学習：非線形決定木モデルにおける特徴量分析手法SPA</h1>
                <p class="text-lg text-stone-600 mt-2">XGBoost, LightGBM, CatBoostなどのモデルの解釈可能性を高めるための分析手法を探る</p>
            </header>

            <section id="introduction" class="content-section prose max-w-none prose-stone prose-headings:text-sky-700 prose-a:text-sky-600 prose-strong:text-stone-900 bg-white p-6 rounded-lg shadow mb-8">
                <h2 class="text-3xl font-semibold mb-4">1. はじめに</h2>
                <p class="mb-4">このセクションでは、XGBoost、LightGBM、CatBoostといった非線形決定木モデルの概要と、それらのモデルにおける「解釈可能性」の重要性について解説します。これらのモデルは高い予測性能を持つ一方で、その内部動作が複雑であるため、「ブラックボックス」と見なされがちです。しかし、医療、金融、法務など、社会的に影響の大きな分野では、予測結果だけでなく、その根拠を理解することが不可欠です。</p>
                <p>XGBoost、LightGBM、CatBoostといった非線形決定木モデルは、その高い予測性能から、金融、医療、製造業など多岐にわたる分野で広く利用されています。これらのモデルは、多数の決定木から構成されるアンサンブルモデルであり、個々の決定木は比較的単純なルールで構成されていますが、全体としてはその内部動作が「ブラックボックス」と見なされがちです [1, 2, 3, 4]。しかし、特に医療診断、金融リスク評価、法的意思決定といった社会的に影響の大きい分野では、予測の正確さだけでなく、その予測がなぜなされたのかという理由を理解する「解釈可能性」が極めて重要となります [1, 2, 5]。モデルの解釈可能性は、信頼性の確保、デバッグ、公平性の検証、規制遵守、そしてドメイン専門家への説明において不可欠な要素です [1, 2, 3, 4]。</p>
                <p>本レポートは、非線形決定木モデルの予測において、特徴量間の相互作用や関係性、各特徴量の役割、特徴量重要度などに注目した分析手法とアプローチについて、信頼性の高い先行研究や論文をまとめ、包括的なレビューを提供することを目的とします。具体的には、SHAP、Permutation Feature Importance、FriedmanのH-statistic、CatBoostの独自機能、Partial Dependence Plots、Individual Conditional Expectation (ICE) Plots、Accumulated Local Effects (ALE) Plots、そしてカテゴリ特徴量エンコーディングの解釈可能性への影響といった主要な手法について、その理論的背景、計算方法、実践例、強みと限界を詳細に解説します。これにより、読者がこれらの強力なモデルをより深く理解し、実世界の課題に応用するための具体的な指針を提供することを目指します。</p>
            </section>

            <section id="feature-importance" class="content-section prose max-w-none prose-stone prose-headings:text-sky-700 prose-a:text-sky-600 prose-strong:text-stone-900 bg-white p-6 rounded-lg shadow mb-8">
                <h2 class="text-3xl font-semibold mb-4">2. 特徴量重要度分析手法</h2>
                <p class="mb-4">このセクションでは、モデルの予測においてどの特徴量がどれほど重要かを評価する主要な手法、SHAP (SHapley Additive exPlanations) と Permutation Feature Importance (PFI) について詳述します。これらの手法は、モデルの解釈と改善に不可欠です。</p>
                
                <h3 class="text-2xl font-semibold mt-6 mb-3">2.1 SHAP (SHapley Additive exPlanations)</h3>
                <p>SHAPは、協力ゲーム理論のShapley値を基盤とし、各特徴量の予測への貢献度を公平に分配する統一的フレームワークです [3, 6, 7, 8, 9]。特に決定木モデル向けのTree SHAPアルゴリズムは効率的に正確な値を計算でき、XGBoostやLightGBM、CatBoostに広く適用されています [5, 6, 10, 11, 12, 13, 14, 15]。SHAPは「一貫性」と「局所的正確性」という特性を持ち、特徴量の影響を信頼性高く評価できます [6, 9, 11, 13]。また、個々の予測（局所的説明）とモデル全体（全体的理解）の両方に対する洞察を提供します [5, 6, 8, 9]。</p>
                <p><strong>代表的な論文:</strong></p>
                <ul>
                    <li>Lundberg, S. M., & Lee, S.-I. (2017). <em>A Unified Approach to Interpreting Model Predictions</em>. NIPS.</li>
                    <li>Lundberg, S. M., Erion, G., & Lee, S.-I. (2020). <em>Consistent Individualized Feature Attribution for Tree Ensembles</em>. ICML.</li>
                </ul>
                <div class="chart-container my-6">
                    <canvas id="shapImportanceChart"></canvas>
                </div>
                <p class="text-sm text-center text-stone-500">図: SHAP値に基づく特徴量重要度の例 (概念図)</p>


                <h3 class="text-2xl font-semibold mt-6 mb-3">2.2 Permutation Feature Importance (PFI)</h3>
                <p>PFIは、特徴量の値をランダムにシャッフルした際のモデル性能の低下度合いで、その特徴量の重要度を評価するモデル非依存的な手法です [17, 18, 19]。あらゆるモデルに適用可能で、通常テストセットで計算されます [18, 19]。ただし、特徴量間に強い相関があると、非現実的なデータ点が生成され結果が歪む可能性があり、Conditional Permutation Importance (CPI) などの対策が提案されています [19, 20]。PFIは予測性能への影響を、SHAPはモデル出力への貢献度を評価するため、両者を組み合わせることで深い理解が得られます [19, 21]。</p>
                <p><strong>代表的な論文:</strong></p>
                <ul>
                    <li>Breiman, L. (2001). <em>Random Forests</em>. Machine Learning.</li>
                    <li>Fisher, A., Rudin, C., & Dominici, F. (2019). <em>All Models Are Wrong, but Many Are Useful</em>. KDD.</li>
                    <li>Strobl, C., et al. (2008). <em>Bias in Random Forest Variable Importance Measures</em>. BMC Bioinformatics.</li>
                </ul>
            </section>

            <section id="feature-interaction" class="content-section prose max-w-none prose-stone prose-headings:text-sky-700 prose-a:text-sky-600 prose-strong:text-stone-900 bg-white p-6 rounded-lg shadow mb-8">
                <h2 class="text-3xl font-semibold mb-4">3. 特徴量相互作用・関係性分析手法</h2>
                <p class="mb-4">ここでは、特徴量間の複雑な相互作用を理解するための手法として、FriedmanのH-statisticとCatBoostの独自機能に焦点を当てます。これにより、モデルがどのようにして予測を行っているかをより深く洞察できます。</p>

                <h3 class="text-2xl font-semibold mt-6 mb-3">3.1 FriedmanのH-statistic</h3>
                <p>FriedmanのH-statisticは、ある特徴量の予測への影響が他の特徴量の値によって変化する「特徴量相互作用」の強さを定量化するモデル非依存的な尺度です [25, 26]。観測された部分依存関数と相互作用がないと仮定した場合の関数との差の分散を測定し、0から1（またはそれ以上）の値で相互作用の強さを示します [25, 26]。計算コストが高い点や、相関特徴量による「見かけ上の相互作用」の検出リスクが課題です [25, 26]。</p>
                <p class="my-2">特徴量 $j$ と $k$ の間の相互作用のH-statistic ($H_{jk}^2$):</p>
                <div class="bg-stone-50 p-3 rounded text-sm overflow-x-auto">
                $H_{jk}^2 = \frac{\sum_{i=1}^n\left[\text{PD}_{jk}(x_j^{(i)},x_k^{(i)}) - \text{PD}_j(x_j^{(i)}) - \text{PD}_k(x_k^{(i)})\right]^2}{\sum_{i=1}^n\left(\text{PD}_{jk}(x_j^{(i)},x_k^{(i)})\right)^2}$
                </div>
                <p class="my-2">特徴量 $j$ と他のすべての特徴量との相互作用のH-statistic ($H_j^2$):</p>
                <div class="bg-stone-50 p-3 rounded text-sm overflow-x-auto">
                $H_j^2 = \frac{\sum_{i=1}^n\left[\hat{f}(\mathbf{x}^{(i)}) - \text{PD}_j(x_j^{(i)}) - \text{PD}_{\setminus j}(\mathbf{x}_{\setminus j}^{(i)})\right]^2}{\sum_{i=1}^n \left(\hat{f}(\mathbf{x}^{(i)})\right)^2}$
                </div>
                <p><strong>代表的な論文:</strong></p>
                <ul>
                    <li>Friedman, J. H., & Popescu, T. (2008). <em>Predictive Learning via Rule Ensembles</em>. The Annals of Applied Statistics.</li>
                </ul>

                <h3 class="text-2xl font-semibold mt-6 mb-3">3.2 CatBoostにおける特徴量相互作用強度</h3>
                <p>CatBoostは、特徴量間の相互作用強度を計算する独自のメカニズムを提供します [15, 30, 31]。ツリー構築プロセスでカテゴリ特徴量の組み合わせを内部的に利用し、高次の依存関係を捉えます [32, 33]。相互作用強度は、モデル内のツリーにおける特徴量ペアの分割を観察することで算出されます [31]。CatBoostは「Interaction」と「InternalInteraction」の二つの概念で相互作用情報を提供し、モデルが実際に学習した特徴量の組み合わせや相互作用を直接的に示します [15, 30, 31]。</p>
                <p><strong>代表的な論文:</strong></p>
                <p>具体的なアルゴリズム論文は明示されていませんが、以下の論文が基盤概念に関連します。</p>
                <ul>
                    <li>Prokhorenkova et al. (2018). <em>CatBoost: unbiased boosting with categorical features</em>. NeurIPS.</li>
                    <li>Dorogush et al. (2017). <em>CatBoost: gradient boosting with categorical features support</em>. arXiv.</li>
                </ul>
            </section>
            
            <section id="individual-feature-analysis" class="content-section prose max-w-none prose-stone prose-headings:text-sky-700 prose-a:text-sky-600 prose-strong:text-stone-900 bg-white p-6 rounded-lg shadow mb-8">
                <h2 class="text-3xl font-semibold mb-4">4. 各特徴量の役割とカテゴリ分類の分析</h2>
                <p class="mb-4">このセクションでは、個々の特徴量がモデルの予測にどのように寄与しているかを理解するための手法、Partial Dependence Plots (PDP)、Individual Conditional Expectation (ICE) Plots、Accumulated Local Effects (ALE) Plots を解説します。これらの手法は、モデルの透明性を高め、挙動を信頼する上で不可欠です。</p>

                <h3 class="text-2xl font-semibold mt-6 mb-3">4.1 Partial Dependence Plots (PDP)</h3>
                <p>PDPは、1つまたは2つの特徴量がモデルの予測出力に平均的にどのような限界効果を与えるかを視覚化するツールです [34, 35, 36]。特徴量と目的変数との関係の形状（線形、単調、複雑など）を明らかにします。主要な限界は、特徴量間の独立性の仮定であり、相関が強いと誤解を招く結果を生む可能性があります [19, 36]。また、平均的な効果のみを示し、異質な関係性を隠蔽することがあります [36, 37]。</p>
                <p class="my-2">部分依存関数 $\text{PD}_S(x_S)$:</p>
                <div class="bg-stone-50 p-3 rounded text-sm overflow-x-auto">
                $\text{PD}_S(x_S) = E_{X_C}[\hat{f}(x_S, X_C)] = \int \hat{f}(x_S, X_C) d\mathbb{P}(X_C)$
                </div>
                <p><strong>代表的な論文:</strong></p>
                <ul>
                    <li>Friedman, J. H. (2001). <em>Greedy Function Approximation: A Gradient Boosting Machine</em>. The Annals of Statistics.</li>
                </ul>

                <h3 class="text-2xl font-semibold mt-6 mb-3">4.2 Individual Conditional Expectation (ICE) Plots</h3>
                <p>ICEプロットは、各インスタンスについて、特定の特徴量の値が変化したときに予測がどう変わるかを示すもので、インスタンスごとに1本の曲線が描かれます [37, 38]。PDPが平均的な効果を示すのに対し、ICEは個別の効果を示し、PDPでは隠蔽されがちな異質な関係性や相互作用を明らかにできます [22, 37, 38]。単一特徴量に限定される、相関問題、多数の曲線による混雑が限界です [37]。Centered ICE (c-ICE) や Derivative ICE (d-ICE) などのバリエーションがあります [37]。</p>
                <p><strong>代表的な論文:</strong></p>
                <ul>
                    <li>Goldstein, A., et al. (2015). <em>Peeking Inside the Black Box: Visualizing Statistical Learning With Plots of Individual Conditional Expectation</em>. Journal of Machine Learning Research.</li>
                </ul>

                <h3 class="text-2xl font-semibold mt-6 mb-3">4.3 Accumulated Local Effects (ALE) Plots</h3>
                <p>ALEプロットは、PDPの限界である特徴量間相関の問題に対処するために開発されたモデル非依存的な手法です [22, 23, 24]。条件付き分布にわたって予測の差分を平均化・累積し、相関する特徴量が存在する場合でも信頼性の高い推定値を提供します [22, 23, 24]。PDPよりも計算効率が良いとされます [22, 23, 24]。2次元ALEプロットは純粋な相互作用効果のみを示します [24]。</p>
                <p><strong>代表的な論文:</strong></p>
                <ul>
                    <li>Apley, D. W. (2016). <em>Visualizing the Effects of Predictor Variables in Black Box Models</em>. arXiv.</li>
                </ul>
            </section>

            <section id="categorical-features" class="content-section prose max-w-none prose-stone prose-headings:text-sky-700 prose-a:text-sky-600 prose-strong:text-stone-900 bg-white p-6 rounded-lg shadow mb-8">
                <h2 class="text-3xl font-semibold mb-4">5. カテゴリ特徴量のエンコーディングと解釈可能性</h2>
                <p class="mb-4">カテゴリ特徴量の適切なエンコーディングは、モデルの性能、解釈可能性、汎化能力に大きく影響します。このセクションでは、主要なエンコーディング手法と、特にCatBoostにおけるカテゴリ特徴量のネイティブな扱いについて解説します。</p>
                <p>主要なエンコーディング手法には、One-Hot Encoding (OHE)、Label Encoding、Target Encoding、Frequency Encoding、Entity Embeddingsなどがあります [39, 40, 41]。それぞれツリーベースモデルへの影響、解釈可能性、課題が異なります。例えば、OHEは解釈しやすいが高カーディナリティ特徴量で次元爆発を起こしやすく [39, 41, 42]、Target Encodingは有効だがデータリーケージのリスクがあります [39, 40]。</p>
                <p>CatBoostは、Ordered Target StatisticsとOrdered Boostingという技術を用いてカテゴリ特徴量をネイティブに処理し、ターゲットリーケージや予測シフトの問題を解決します [13, 32, 33, 39]。これにより、手動エンコーディングの課題を軽減し、高次の相互作用を自動的に捉えることができます [30, 32]。</p>
                <p class="mt-4">詳細は「7. 手法比較表」のTable 2: カテゴリ特徴量エンコーディング手法の比較 を参照してください。</p>
            </section>

            <section id="practical-approach" class="content-section prose max-w-none prose-stone prose-headings:text-sky-700 prose-a:text-sky-600 prose-strong:text-stone-900 bg-white p-6 rounded-lg shadow mb-8">
                <h2 class="text-3xl font-semibold mb-4">6. 複数の解釈手法の組み合わせと実践的アプローチ</h2>
                <p class="mb-4">単一の解釈手法には限界があるため、複数の手法を組み合わせることで、モデルの振る舞いに関するより包括的で多角的な視点を得ることが不可欠です [5, 21, 45, 46]。このセクションでは、その組み合わせ方や、実践的な分析ワークフローについて提案します。</p>
                <p>例えば、SHAPとPFIを組み合わせてモデル利用特徴量と真に重要な特徴量を比較したり [21]、PDPとICEを組み合わせて平均効果と個別効果を理解したりできます [22, 37]。近年は、予測性能と解釈性のトレードオフを克服するハイブリッドモデルも注目されています [45, 46, 47]。</p>
                <p>XAI手法は「関連性」を示しますが、直接的な「因果関係」を推定するものではありません [48]。しかし、複数の手法を組み合わせることで、影響の方向性や相互依存性について、より因果に近い示唆を得る手がかりとなります。ただし、真の因果関係確立には厳密な検証が必要です。</p>
                <p>多くのXAI手法には「不安定性」や「堅牢性」の課題があり [19, 25, 49, 50, 51, 52]、信頼性と実用性を向上させる研究が進んでいます。Conditional PFIやALEプロットはその一例です [19, 20, 22, 23, 24]。</p>
                <h3 class="text-2xl font-semibold mt-6 mb-3">実践的な分析ワークフローの提案:</h3>
                <ol class="list-decimal pl-5 space-y-2">
                    <li><strong>全体的な特徴量重要度の把握:</strong> SHAPサマリープロットやPFIでグローバルな重要度を把握。</li>
                    <li><strong>主要な特徴量の役割の深掘り:</strong> PDPやALEプロット（ALE優先）で平均的影響を視覚化。</li>
                    <li><strong>異質な効果と相互作用の発見:</strong> ICEプロットで個別効果を探索。SHAP Interaction ValuesやH-statistic、CatBoost機能で相互作用を評価。</li>
                    <li><strong>カテゴリ特徴量の詳細分析:</strong> エンコーディング手法の影響を考慮し、必要に応じて試行。</li>
                    <li><strong>ドメイン知識との照合:</strong> 得られた解釈を専門家と共有し、信頼性を高め、意思決定に活用。</li>
                </ol>
            </section>
            
            <section id="comparison-tables" class="content-section bg-white p-6 rounded-lg shadow mb-8">
                <h2 class="text-3xl font-semibold mb-4 text-sky-700">7. 手法比較表</h2>
                <p class="mb-6 text-stone-700">このセクションでは、レポート内で言及されている主要な特徴量分析手法とカテゴリ特徴量エンコーディング手法の比較表を提示します。各手法の目的、特性、長所、短所を一覧で確認することで、状況に応じた適切な手法選択の助けとなります。</p>

                <h3 class="text-2xl font-semibold mt-6 mb-3 text-sky-700">Table 1: 主要な特徴量分析手法の比較</h3>
                <div class="overflow-x-auto">
                    <table class="min-w-full table-auto border-collapse border border-stone-300">
                        <thead class="bg-stone-100">
                            <tr>
                                <th class="p-3 border border-stone-300 text-left text-sm font-semibold text-stone-700">手法名</th>
                                <th class="p-3 border border-stone-300 text-left text-sm font-semibold text-stone-700">目的</th>
                                <th class="p-3 border border-stone-300 text-left text-sm font-semibold text-stone-700">モデル依存性</th>
                                <th class="p-3 border border-stone-300 text-left text-sm font-semibold text-stone-700">ローカル/グローバル</th>
                                <th class="p-3 border border-stone-300 text-left text-sm font-semibold text-stone-700">特徴量相互作用の扱い</th>
                                <th class="p-3 border border-stone-300 text-left text-sm font-semibold text-stone-700">強み</th>
                                <th class="p-3 border border-stone-300 text-left text-sm font-semibold text-stone-700">限界</th>
                                <th class="p-3 border border-stone-300 text-left text-sm font-semibold text-stone-700">代表的な論文 (発表年, 著者)</th>
                            </tr>
                        </thead>
                        <tbody class="text-stone-700 text-sm">
                            <tr>
                                <td class="p-3 border border-stone-300"><strong>SHAP</strong></td>
                                <td class="p-3 border border-stone-300">個々の予測への特徴量貢献度、全体的な重要度</td>
                                <td class="p-3 border border-stone-300">モデル非依存 (Tree SHAPはツリーモデルに特化)</td>
                                <td class="p-3 border border-stone-300">ローカル & グローバル</td>
                                <td class="p-3 border border-stone-300">Shapley Interaction Valuesで定量化</td>
                                <td class="p-3 border border-stone-300">一貫性、局所的正確性、統一的フレームワーク、ツリーモデルで効率的</td>
                                <td class="p-3 border border-stone-300">計算コスト (大規模モデル/データ)、複雑な解釈</td>
                                <td class="p-3 border border-stone-300">Lundberg & Lee (2017)</td>
                            </tr>
                            <tr>
                                <td class="p-3 border border-stone-300"><strong>Permutation Feature Importance (PFI)</strong></td>
                                <td class="p-3 border border-stone-300">モデル性能への特徴量の影響度、全体的な重要度</td>
                                <td class="p-3 border border-stone-300">モデル非依存</td>
                                <td class="p-3 border border-stone-300">グローバル</td>
                                <td class="p-3 border border-stone-300">主効果と相互作用効果を包含</td>
                                <td class="p-3 border border-stone-300">直感的な解釈、モデル非依存、再学習不要</td>
                                <td class="p-3 border border-stone-300">相関する特徴量に弱い、非現実的なデータ生成、ランダム性</td>
                                <td class="p-3 border border-stone-300">Breiman (2001), Fisher et al. (2019)</td>
                            </tr>
                            <tr>
                                <td class="p-3 border border-stone-300"><strong>FriedmanのH-statistic</strong></td>
                                <td class="p-3 border border-stone-300">特徴量相互作用の強さの定量化</td>
                                <td class="p-3 border border-stone-300">モデル非依存</td>
                                <td class="p-3 border border-stone-300">グローバル</td>
                                <td class="p-3 border border-stone-300">相互作用の強さを定量化</td>
                                <td class="p-3 border border-stone-300">無次元で比較可能、あらゆる相互作用を検出</td>
                                <td class="p-3 border border-stone-300">計算コスト高、相関する特徴量に弱い、解釈が難しい (&gt;1の場合)</td>
                                <td class="p-3 border border-stone-300">Friedman & Popescu (2008)</td>
                            </tr>
                            <tr>
                                <td class="p-3 border border-stone-300"><strong>CatBoost Feature Interaction Strength</strong></td>
                                <td class="p-3 border border-stone-300">CatBoostモデルが利用する特徴量相互作用の強さ</td>
                                <td class="p-3 border border-stone-300">モデル固有</td>
                                <td class="p-3 border border-stone-300">グローバル</td>
                                <td class="p-3 border border-stone-300">内部的に利用する相互作用を定量化</td>
                                <td class="p-3 border border-stone-300">CatBoostのネイティブ処理による正確な相互作用検出</td>
                                <td class="p-3 border border-stone-300">CatBoostモデルに限定、他のモデルとの直接比較は困難</td>
                                <td class="p-3 border border-stone-300">Prokhorenkova et al. (2018) など</td>
                            </tr>
                            <tr>
                                <td class="p-3 border border-stone-300"><strong>Partial Dependence Plots (PDP)</strong></td>
                                <td class="p-3 border border-stone-300">特定の特徴量が予測に与える平均的な影響</td>
                                <td class="p-3 border border-stone-300">モデル非依存</td>
                                <td class="p-3 border border-stone-300">グローバル</td>
                                <td class="p-3 border border-stone-300">相互作用を内包するが、隠蔽する可能性</td>
                                <td class="p-3 border border-stone-300">直感的な可視化、平均的な関係性を把握</td>
                                <td class="p-3 border border-stone-300">独立性の仮定、異質な効果の隠蔽、相関する特徴量に弱い</td>
                                <td class="p-3 border border-stone-300">Friedman (2001)</td>
                            </tr>
                            <tr>
                                <td class="p-3 border border-stone-300"><strong>Individual Conditional Expectation (ICE) Plots</strong></td>
                                <td class="p-3 border border-stone-300">各インスタンスにおける特徴量の予測への影響</td>
                                <td class="p-3 border border-stone-300">モデル非依存</td>
                                <td class="p-3 border border-stone-300">ローカル</td>
                                <td class="p-3 border border-stone-300">異質な相互作用の発見</td>
                                <td class="p-3 border border-stone-300">異質な関係性を明確に可視化、直感的</td>
                                <td class="p-3 border border-stone-300">単一特徴量に限定、混雑しやすい、相関する特徴量に弱い</td>
                                <td class="p-3 border border-stone-300">Goldstein et al. (2015)</td>
                            </tr>
                            <tr>
                                <td class="p-3 border border-stone-300"><strong>Accumulated Local Effects (ALE) Plots</strong></td>
                                <td class="p-3 border border-stone-300">特定の特徴量が予測に与える平均的な影響</td>
                                <td class="p-3 border border-stone-300">モデル非依存</td>
                                <td class="p-3 border border-stone-300">グローバル</td>
                                <td class="p-3 border border-stone-300">相関を考慮した相互作用の可視化</td>
                                <td class="p-3 border border-stone-300">相関する特徴量に堅牢、PDPより高速、純粋な相互作用効果を表示</td>
                                <td class="p-3 border border-stone-300">実装が複雑、ICE曲線がない、高次元相互作用の可視化困難</td>
                                <td class="p-3 border border-stone-300">Apley (2016)</td>
                            </tr>
                        </tbody>
                    </table>
                </div>

                <h3 class="text-2xl font-semibold mt-10 mb-3 text-sky-700">Table 2: カテゴリ特徴量エンコーディング手法の比較</h3>
                <div class="overflow-x-auto">
                    <table class="min-w-full table-auto border-collapse border border-stone-300">
                        <thead class="bg-stone-100">
                            <tr>
                                <th class="p-3 border border-stone-300 text-left text-sm font-semibold text-stone-700">手法名</th>
                                <th class="p-3 border border-stone-300 text-left text-sm font-semibold text-stone-700">説明</th>
                                <th class="p-3 border border-stone-300 text-left text-sm font-semibold text-stone-700">ツリーベースモデルへの影響</th>
                                <th class="p-3 border border-stone-300 text-left text-sm font-semibold text-stone-700">解釈可能性</th>
                                <th class="p-3 border border-stone-300 text-left text-sm font-semibold text-stone-700">課題</th>
                            </tr>
                        </thead>
                        <tbody class="text-stone-700 text-sm">
                            <tr>
                                <td class="p-3 border border-stone-300"><strong>One-Hot Encoding (OHE)</strong></td>
                                <td class="p-3 border border-stone-300">各カテゴリをバイナリのダミー変数に変換</td>
                                <td class="p-3 border border-stone-300">適切だが、高カーディナリティで次元増加、スパース化</td>
                                <td class="p-3 border border-stone-300">比較的良好 (各カテゴリが独立変数)</td>
                                <td class="p-3 border border-stone-300">高次元化、メモリ消費、過学習リスク (高カーディナリティ)</td>
                            </tr>
                            <tr>
                                <td class="p-3 border border-stone-300"><strong>Label Encoding</strong></td>
                                <td class="p-3 border border-stone-300">各カテゴリに一意の整数を割り当て</td>
                                <td class="p-3 border border-stone-300">人工的な順序関係を導入し、モデルを誤解させる可能性</td>
                                <td class="p-3 border border-stone-300">低い (順序関係がないカテゴリに順序を付与)</td>
                                <td class="p-3 border border-stone-300">順序関係の誤認、モデル性能低下</td>
                            </tr>
                            <tr>
                                <td class="p-3 border border-stone-300"><strong>Target Encoding (Mean Encoding)</strong></td>
                                <td class="p-3 border border-stone-300">各カテゴリを目的変数の平均値で置き換え</td>
                                <td class="p-3 border border-stone-300">高カーディナリティに有効、性能向上に寄与</td>
                                <td class="p-3 border border-stone-300">低い (元のカテゴリ意味が数値に変換される)</td>
                                <td class="p-3 border border-stone-300">データリーケージ、過学習リスク (要交差検証と正則化)</td>
                            </tr>
                            <tr>
                                <td class="p-3 border border-stone-300"><strong>Frequency Encoding</strong></td>
                                <td class="p-3 border border-stone-300">各カテゴリをその出現頻度でエンコード</td>
                                <td class="p-3 border border-stone-300">高カーディナリティに有効、次元削減</td>
                                <td class="p-3 border border-stone-300">中程度 (頻度でカテゴリの相対的重要性を把握)</td>
                                <td class="p-3 border border-stone-300">複雑な関係性を捉えにくい、同じ頻度のカテゴリの区別不可</td>
                            </tr>
                            <tr>
                                <td class="p-3 border border-stone-300"><strong>Entity Embeddings</strong></td>
                                <td class="p-3 border border-stone-300">ディープラーニングでカテゴリの密なベクトル表現を学習</td>
                                <td class="p-3 border border-stone-300">ツリーベースモデルには直接適用しにくい (NN向け)</td>
                                <td class="p-3 border border-stone-300">非常に低い (抽象的な数値表現)</td>
                                <td class="p-3 border border-stone-300">計算コスト高、大規模データが必要、解釈が困難</td>
                            </tr>
                            <tr>
                                <td class="p-3 border border-stone-300"><strong>CatBoost Native Handling</strong></td>
                                <td class="p-3 border border-stone-300">Ordered Target StatisticsとOrdered Boostingでカテゴリを直接処理</td>
                                <td class="p-3 border border-stone-300">ターゲットリーケージなく高カーディナリティを効率的に処理</td>
                                <td class="p-3 border border-stone-300">良好 (モデル内部で最適な分割を学習)</td>
                                <td class="p-3 border border-stone-300">CatBoostモデルに限定</td>
                            </tr>
                        </tbody>
                    </table>
                </div>
            </section>


            <section id="summary" class="content-section prose max-w-none prose-stone prose-headings:text-sky-700 prose-a:text-sky-600 prose-strong:text-stone-900 bg-white p-6 rounded-lg shadow mb-8">
                <h2 class="text-3xl font-semibold mb-4">8. まとめと今後の展望</h2>
                <p class="mb-4">本レポートでレビューした主要な解釈手法の要約と、今後の研究課題や発展の方向性について概説します。これらの取り組みは、機械学習モデルの信頼性と社会受容性を高める上で重要です。</p>
                <p>本レポートでは、XGBoost、LightGBM、CatBoostなどの非線形決定木モデルの予測を解釈するための主要な手法を詳細にレビューしました。SHAP、PFI、H-statistic、CatBoost独自機能、PDP、ICE、ALE、カテゴリ特徴量エンコーディングなどが含まれます。これらの手法は、特徴量重要度、相互作用、各特徴量の役割の分析に役立ちます。</p>
                <h3 class="text-2xl font-semibold mt-6 mb-3">今後の研究課題と発展の方向性:</h3>
                <ul class="list-disc pl-5 space-y-1">
                    <li><strong>堅牢性と安定性の向上:</strong> 既存手法の不安定性や堅牢性の課題解決。</li>
                    <li><strong>因果推論との統合:</strong> 真の因果関係特定のため、因果推論フレームワークとの統合。</li>
                    <li><strong>高次元・複雑データへの対応:</strong> テキスト、画像、時系列データなどへの適応研究。</li>
                    <li><strong>ユーザー中心のXAI:</strong> 非技術者にも直感的に理解できるインターフェース開発。</li>
                    <li><strong>モデル間の比較と選択の指針:</strong> 最適な手法選択のためのガイドラインや自動化。</li>
                </ul>
                <p>これらの課題への継続的な取り組みは、機械学習モデルが社会に広く受け入れられ、信頼されるための基盤を強化することに貢献するでしょう。</p>
            </section>
            
            <footer class="text-center mt-12 py-6 border-t border-stone-300">
                <p class="text-sm text-stone-500">&copy; 2024 解釈可能な機械学習SPA. All rights reserved.</p>
            </footer>

        </main>
    </div>

    <script>
        document.addEventListener('DOMContentLoaded', function () {
            const navLinks = document.querySelectorAll('.nav-link');
            const contentSections = document.querySelectorAll('.content-section');
            let currentChart = null;

            function setActiveSection(hash) {
                navLinks.forEach(link => {
                    link.classList.remove('active');
                    if (link.getAttribute('href') === hash) {
                        link.classList.add('active');
                    }
                });

                contentSections.forEach(section => {
                    section.classList.remove('active');
                    if ("#" + section.id === hash) {
                        section.classList.add('active');
                    }
                });

                // Specific logic for chart rendering when its section is active
                if (hash === '#feature-importance') {
                    renderShapImportanceChart();
                } else {
                    if (currentChart) {
                       // currentChart.destroy(); // Consider destroying if charts are complex and numerous
                       // currentChart = null;
                    }
                }
            }
            
            // Initial section display based on hash or default
            const initialHash = window.location.hash || '#introduction';
            setActiveSection(initialHash);

            navLinks.forEach(link => {
                link.addEventListener('click', function (e) {
                    // e.preventDefault(); // Keep default behavior to update hash
                    const targetId = this.getAttribute('href');
                    setActiveSection(targetId);
                    // window.location.hash = targetId; // Already handled by default anchor behavior
                });
            });

            // Handle hash changes (e.g. browser back/forward buttons)
            window.addEventListener('hashchange', function() {
                setActiveSection(window.location.hash);
            });


            function renderShapImportanceChart() {
                const ctx = document.getElementById('shapImportanceChart');
                if (!ctx) return;
                if (currentChart && currentChart.canvas.id === 'shapImportanceChart') { // Avoid re-rendering if already there
                    return;
                }
                 if (currentChart) { // Destroy previous chart instance if any
                    currentChart.destroy();
                }

                const data = {
                    labels: ['特徴量 A', '特徴量 B', '特徴量 C', '特徴量 D', '特徴量 E'],
                    datasets: [{
                        label: 'SHAP重要度 (例)',
                        data: [0.45, 0.30, 0.15, 0.07, 0.03],
                        backgroundColor: [
                            'rgba(54, 162, 235, 0.6)', // sky-500
                            'rgba(75, 192, 192, 0.6)', // teal-500
                            'rgba(255, 206, 86, 0.6)', // yellow-400
                            'rgba(153, 102, 255, 0.6)', // purple-500
                            'rgba(255, 159, 64, 0.6)'  // orange-500
                        ],
                        borderColor: [
                            'rgba(54, 162, 235, 1)',
                            'rgba(75, 192, 192, 1)',
                            'rgba(255, 206, 86, 1)',
                            'rgba(153, 102, 255, 1)',
                            'rgba(255, 159, 64, 1)'
                        ],
                        borderWidth: 1
                    }]
                };
                const config = {
                    type: 'bar',
                    data: data,
                    options: {
                        indexAxis: 'y',
                        responsive: true,
                        maintainAspectRatio: false,
                        plugins: {
                            legend: {
                                display: true,
                                position: 'top',
                            },
                            title: {
                                display: true,
                                text: 'SHAP値に基づく特徴量重要度（概念図）',
                                font: { size: 16 }
                            },
                            tooltip: {
                                callbacks: {
                                    label: function(context) {
                                        let label = context.dataset.label || '';
                                        if (label) {
                                            label += ': ';
                                        }
                                        if (context.parsed.x !== null) {
                                            label += context.parsed.x.toFixed(2);
                                        }
                                        return label;
                                    }
                                }
                            }
                        },
                        scales: {
                            x: {
                                beginAtZero: true,
                                title: {
                                    display: true,
                                    text: '平均 |SHAP値| (影響の大きさ)'
                                }
                            },
                            y: {
                                ticks: {
                                    autoSkip: false,
                                     callback: function(value, index, values) {
                                        const label = this.getLabelForValue(value);
                                        if (label.length > 16) {
                                            return label.substring(0, 16) + '...';
                                        }
                                        return label;
                                    }
                                }
                            }
                        }
                    }
                };
                currentChart = new Chart(ctx, config);
            }
        });
    </script>
</body>
</html>
